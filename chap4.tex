\chapter{Applications of LCA for Machine Learning}

\section{Unsupervised feature learning}
We evolved a visual sense to allow us to understand the external causes of incident light. The sensor modality is not designed to construct a veridical representation of the world [Gollisch and Meister 2010]. Instead, it is designed to allow us to identify objects of significance and act upon them. Our visual system is intimately connected with the statistics of light as it propagates through our natural world. These statistics have been analyzed extensively by scientists exploring images and videos of natural scenes [refs]. The sparse coding model represents an attempt to build on the knowledge gained from studying the statistics of natural scenes [field gabor paper] to better understand our visual system [olshausen 1996]. In the field of visual unsupervised machine learning, a cornucopia of models have been proposed to learn the statistics of natural scenes without human labels, or "supervision". It is important to recognize that the unsupervised objective function of most of these models does in fact ask for a veridical representation of the inputs, without any real consideration for other ecological significance for the latent code produced. None the less, when combine with a family of constraints that include minimum entropy, maximum compression, and minimal energy expenditure, autoencoder models can exhibit interesting properties that are also found in biological vision systems. In this chapter, we consider the LCA as an autoencoder. Like an autoencoder, the LCA receives inputs, transforms them into a latent code, and it produces reconstructions. We are interested in understanding how useful LCA can be for the machine learning field. One way to assess this is to look at semi-supervised learning. Here the objective is the same as for supervised learning, where we want to associate images with some predetermined category label. However, the catch is that many of the training images do not have ground truth labels assigned to them. A fully supervised model would not be able to use these, and would suffer from limited training examples. Here we show that LCA can be used as an agent to improve semi-supervised learning results. We also demonstrate how an alternate objective, like labeling objects in the world, can be used in the LCA dynamics to modify inference and dictionary learning.

Sparse coding is a model for unsupervised feature learning. Other models also exist.

\subsection{LISTA}
Learned ISTA.

\subsection{DrSAE}
Converges to SC solution.

\section{Semi-Supervised Learning}
Learning unsupervised activations can be used for semi-supervised learning. Human labels are extremely expensive. An ideal model should learn to categorize (e.g. cluster) data without ground-truth labels while still maintaining a faithful representation. As we demonstrated in chapter \ref{ch:iso}, sparse coding produces a code that is both descriptive and faithful to the image content. Here, we wish to modify the sparse coding model to utilize limited label information about an input scene. Typically in sparse coding the sparsity enforcing term is applied uniformly, penalizing all nodes. Instead of the prior limiting the total activation, we want the prior to encourage some nodes to be active based on expectations propagated down from previous layers. These previous layers will focus on grouping inputs into similar categories. We will incorporate a new loss function to encourage unsupervised clustering. This loss function minimizes the output entropy per image, but maximizes it per batch. The intuition is that minimizing entropy per image will force the network to place the image into a category, since the number of output nodes is small (e.g. ~10 for MNIST). Maximizing the entropy across batches is intended to prevent the network from placing all images into a single category. We will add a second layer on top of the LCA network and enforce a categorical cost. The cost is cross-entropy when there is a label or the combined entropy terms described earlier when there is not. Taking the derivative of this new cost with respect to a neuron will give us a new update rule for inference.
[https://docs.google.com/presentation/d/1Dy_Dy1uSnLC3FEWXczgdKGxSejRUYQmfHnwPtY5LA8Y/edit#slide=id.g12e96bb738_0_271]
[https://docs.google.com/presentation/d/1CcFmB1AUIEWU_rKtIaiRM79QGMetjYhnjKfv58hDD8Y/edit#slide=id.g19049d0ee0_0_22]