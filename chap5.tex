\chapter{Hierarchical LCA}


\section{Related hierarchical sparse coding models}


\subsection{Hierarchy architecture is emergent}
\citet{rolfe2013discriminative} outline an unconstrained method for learning representations from natural scenes. Their result provides support for the assumptions made in the Sparse Coding model. They show that the encoding and decoding matrices learn to be approximately transposes of one another and that the lateral inhibition matrix learns to be the Gramian matrix from equation \ref{eq:lca}. What's more, when semi-supervised training is performed, the model learns an emergent hierarchical architecture. We will explore this further in chapter \ref{ch:applications}.
[https://docs.google.com/presentation/d/1bW__4dYIlrrbiV55Y1WdKcI_jxYqCSPXVpQjnumrDfo/edit#slide=id.g13eab2f708_0_83 slide 11]


\subsection{Deconvolutional Competitive Algorithm}
Talk about DCA


\subsection{The Sparse Manifold Transform}
Talk about SMT


\section{Subspace LCA}
Talk about this work.